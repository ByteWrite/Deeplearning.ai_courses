{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bb3b2c-faeb-41ec-8499-508a8bc71b76",
   "metadata": {},
   "source": [
    "# L1: Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a61c8-d1bc-4c93-b1aa-05c1070fb52d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a39a02-fc59-4c46-ad00-0691bdf11fb5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6851df66-ded3-40f2-b252-c680a32921de",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1553d4059243d1acfbcd4639142146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e38d780b474908b5fd34094c4566b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba94b1914954adc899c0c8e0d9b5c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05fa2323aed4d76a9fab1289ae58950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43501b5bd7474a959e36ef56108aead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101d5b51c9354b69936f73283da8efc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837dbb3bf714405bb87627fc60d58e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70b9f56f30d44ff96038775176852a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46ee6f2e87b4b4fa5ae34e9e0283848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395d496b75f74801ae0062a58835268e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a0283f8d24478eb944001e6887ef74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6938626-dba6-454f-a150-f560144a14c5",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd44f86-2aab-46f1-99ec-ea73eac92c7d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5232, 2939, 1037, 2146, 3328,  102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = model.tokenize([\"walker walked a long walk\"])\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74912810-c4ef-4373-86d6-77a095ef01ec",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'walker', 'walked', 'a', 'long', 'walk', '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.convert_ids_to_tokens(tokenized_data[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22aced61-6e22-4ebe-bd35-60509e744aa2",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer consists of multiple stack modules. Tokens are an input\n",
    "# of the first one, so we can ignore the rest.\n",
    "first_module = model._first_module()\n",
    "first_module.auto_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31f2b1-a552-4074-b8f6-baac9a3afed7",
   "metadata": {},
   "source": [
    "## Input token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdde63-90d6-493c-8316-96869c366a99",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "embeddings = first_module.auto_model.embeddings\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e11176-0f9c-40e2-bbe0-fc9da008e70c",
   "metadata": {
    "height": 408
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.express as px\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")  # Use MPS for Apple, CUDA for others, or fallback to CPU\n",
    "\n",
    "first_sentence = \"vector search optimization\"\n",
    "second_sentence = \"we learn to apply vector search optimization\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Tokenize both texts\n",
    "    first_tokens = model.tokenize([first_sentence])\n",
    "    second_tokens = model.tokenize([second_sentence])\n",
    "    \n",
    "    # Get the corresponding embeddings\n",
    "    first_embeddings = embeddings.word_embeddings(\n",
    "        first_tokens[\"input_ids\"].to(device)\n",
    "    )\n",
    "    second_embeddings = embeddings.word_embeddings(\n",
    "        second_tokens[\"input_ids\"].to(device)\n",
    "    )\n",
    "\n",
    "first_embeddings.shape, second_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc85bd-53c6-41b6-8fba-062ba9f82661",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "distances = util.cos_sim(\n",
    "    first_embeddings.squeeze(), \n",
    "    second_embeddings.squeeze()\n",
    ").cpu().numpy() # Move the tensor to the CPU and convert to a NumPy array\n",
    "\n",
    "px.imshow(\n",
    "    distances, \n",
    "    x=model.tokenizer.convert_ids_to_tokens(\n",
    "        second_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    y=model.tokenizer.convert_ids_to_tokens(\n",
    "        first_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    text_auto=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175aa3d9-3daf-46b9-ace7-8a95b3462ffd",
   "metadata": {},
   "source": [
    "### Visualizing the input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc73f36-ce2c-45d6-b2e6-834e7b7fe24d",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "token_embeddings = first_module.auto_model \\\n",
    "    .embeddings \\\n",
    "    .word_embeddings \\\n",
    "    .weight \\\n",
    "    .detach() \\\n",
    "    .cpu() \\\n",
    "    .numpy()\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9f6ec-7612-4fc0-9de5-fe9af772e8b4",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "vocabulary = first_module.tokenizer.get_vocab()\n",
    "sorted_vocabulary = sorted(\n",
    "    vocabulary.items(), \n",
    "    key=lambda x: x[1],  # uses the value of the dictionary entry\n",
    ")\n",
    "sorted_tokens = [token for token, _ in sorted_vocabulary]\n",
    "random.choices(sorted_tokens, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbd3ce-49e3-455d-8a2d-a7a3bd4658cf",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42)\n",
    "tsne_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
    "tsne_embeddings_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4b03d-a3b8-4456-9615-3e4bf86ed19e",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "token_colors = []\n",
    "for token in sorted_tokens:\n",
    "    if token[0] == \"[\" and token[-1] == \"]\":\n",
    "        token_colors.append(\"red\")\n",
    "    elif token.startswith(\"##\"):\n",
    "        token_colors.append(\"blue\")\n",
    "    else:\n",
    "        token_colors.append(\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99b0fe-8723-4193-aec4-7af50f4d296d",
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "scatter = go.Scattergl(\n",
    "    x=tsne_embeddings_2d[:, 0], \n",
    "    y=tsne_embeddings_2d[:, 1],\n",
    "    text=sorted_tokens,\n",
    "    marker=dict(color=token_colors, size=3),\n",
    "    mode=\"markers\",\n",
    "    name=\"Token embeddings\",\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(\n",
    "    data=[scatter],\n",
    "    layout=dict(\n",
    "        width=600,\n",
    "        height=900,\n",
    "        margin=dict(l=0, r=0),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac92ec-0aa1-4582-8c54-db33f024bc63",
   "metadata": {},
   "source": [
    "## Output token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abca87e-db68-498e-b137-d00a77f034b3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "output_embedding = model.encode([\"walker walked a long walk\"])\n",
    "output_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5ca5b-3b56-4b17-b647-d91bf0a6b33e",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "output_token_embeddings = model.encode(\n",
    "    [\"walker walked a long walk\"], \n",
    "    output_value=\"token_embeddings\"\n",
    ")\n",
    "output_token_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963521e9-bab7-4021-b21a-4775f38c994b",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "first_sentence = \"vector search optimization\"\n",
    "second_sentence = \"we learn to apply vector search optimization\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    first_tokens = model.tokenize([first_sentence])\n",
    "    second_tokens = model.tokenize([second_sentence])\n",
    "    \n",
    "    first_embeddings = model.encode(\n",
    "        [first_sentence], \n",
    "        output_value=\"token_embeddings\"\n",
    "    )\n",
    "    second_embeddings = model.encode(\n",
    "        [second_sentence], \n",
    "        output_value=\"token_embeddings\"\n",
    "    )\n",
    "\n",
    "distances = util.cos_sim(\n",
    "    first_embeddings[0], \n",
    "    second_embeddings[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500af15-5de5-498b-b098-6d1554783257",
   "metadata": {
    "height": 204
   },
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    distances.cpu().numpy(),  # Move the tensor to CPU and convert to a NumPy array\n",
    "    x=model.tokenizer.convert_ids_to_tokens(\n",
    "        second_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    y=model.tokenizer.convert_ids_to_tokens(\n",
    "        first_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    text_auto=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffe74e-968f-4b37-ab73-5686c18a8af7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee843700-b778-4af3-901c-53d420b12f51",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a62bb-7713-4e88-acb1-621e1da38203",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3e6cc-4787-4922-a0f9-e98ac5eac5b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db97e61-b26b-4628-bebd-94290afe3d45",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687670ec-9c81-4305-bb7e-377de2d50afa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfba8a-6d99-4d12-b786-2a0a5fc9f0d4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
